{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def file_config(start_url, i=2):\n",
    "    # Configuration du driver\n",
    "    driver_path = r\"/usr/local/bin/chromedriver\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--headless')\n",
    "    driver = webdriver.Chrome(executable_path=driver_path, options=options)\n",
    "    driver.set_page_load_timeout(6000)\n",
    "    attempts = i\n",
    "    while attempts >0:\n",
    "        try :\n",
    "            driver.get(start_url)\n",
    "            driver.maximize_window()\n",
    "            attempts = 0\n",
    "        except TimeoutException:\n",
    "            attempts = attempts - 1\n",
    "    return driver\n",
    "\n",
    "\n",
    "driver = file_config(start_url = r'https://aici.ci/fr/recherche-immobilier?typeoffre=3&typebien=All&field_nbre_pieces=All&page=0')\n",
    "\n",
    "wait = WebDriverWait(driver, 100)\n",
    "\n",
    "data = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(cards):\n",
    "    links = []\n",
    "    for card in cards:\n",
    "        link = card.find_element(By.CSS_SELECTOR, 'div.col-sm-12.bien-ville_titre > div.bien-titre > a').get_attribute('href')\n",
    "        links.append(link)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        localisation = soup.select_one(\"div.col-sm-12.bien-ville_titre > div.bien_ville\").text.strip()\n",
    "\n",
    "    for link in links:\n",
    "        attempts = 3\n",
    "        while attempts >0:\n",
    "            try :\n",
    "                driver.get(link)\n",
    "                driver.refresh()\n",
    "                attempts = 0\n",
    "            except TimeoutException:\n",
    "                attempts = attempts - 1\n",
    "\n",
    "\n",
    "        # Utilisation de BeautifulSoup pour récupérer les détails de l'annonce\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "        try :\n",
    "            details = soup.select_one('body > div.dialog-off-canvas-main-canvas > div.main-container.container.js-quickedit-main-content > div > section > div.region.region-content > article > div')\n",
    "        except AttributeError:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            price = soup.select_one(\"div.row.bs-2col-bricked > div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-prix-en-fcfa.clearfix > div\").text.strip()\n",
    "            title = soup.select_one(\"div.row.bs-2col-bricked > div.col-sm-8.bs-region.bs-region--top-left > section.block.block-layout-builder.block-field-blocknodebiens-immobilierstitle.clearfix > span\").text.strip()\n",
    "        except AttributeError:\n",
    "          continue\n",
    "\n",
    "        immo_type = details.select_one(\"div.row.bs-2col-bricked > div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-type-de-bien.clearfix > div\").text.strip()\n",
    "        # from details_group2\n",
    "        try:\n",
    "            superficie = f\"{details.select_one('div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-surface.clearfix').text.strip()}\"\n",
    "            nb_pieces = details.select_one('div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-nbre-pieces.clearfix').text.strip()\n",
    "            nb_salle_de_bain = details.select_one('div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-salles-bain.clearfix').text.strip()\n",
    "        except AttributeError:\n",
    "            try:\n",
    "                superficie = None\n",
    "                nb_pieces = details.select_one('div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-nbre-pieces.clearfix').text.strip()\n",
    "                nb_salle_de_bain = details.select_one('div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-salles-bain.clearfix').text.strip()\n",
    "            except AttributeError:\n",
    "                try:\n",
    "                    nb_pieces = f\"{details.select_one('div.col-sm-4.bs-region.bs-region--top-right > section.block.block-layout-builder.block-field-blocknodebiens-immobiliersfield-nbre-pieces.clearfix').text.strip()}\"\n",
    "                    superficie = None\n",
    "                    nb_salle_de_bain = None\n",
    "                except AttributeError:\n",
    "                    superficie = None\n",
    "                    nb_pieces = None\n",
    "                    nb_salle_de_bain = None\n",
    "\n",
    "        # from details_group3\n",
    "        try:\n",
    "            description = details.select_one('div.col-sm-8.bs-region.bs-region--top-left').text.strip().replace('\\n', ' ')\n",
    "        except AttributeError:\n",
    "            description = None\n",
    "\n",
    "        annonceur = \"AICI\"\n",
    "        current_datetime = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        data.append({\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'localisation': localisation,\n",
    "            'superficie': superficie,\n",
    "            \"type d'immobilier\": immo_type,\n",
    "            'nb_pieces': nb_pieces,\n",
    "            \"nb_salle_de_bain\": nb_salle_de_bain,\n",
    "            'scraping_date': current_datetime,\n",
    "            \"annonceur\" : annonceur,\n",
    "            \"link\" : link,\n",
    "            'description': description\n",
    "        })\n",
    "\n",
    "        print(data[-1])\n",
    "        print(len(data))\n",
    "\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "\n",
    "    try:\n",
    "        # Attendre que les éléments soient visibles\n",
    "        cards_presence = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, '#views-bootstrap-recherche-immobilier-page-1')))\n",
    "        # Créer une liste de cartes\n",
    "        cards = cards_presence.find_elements(By.CSS_SELECTOR, 'div > div > div.views-field.views-field-nothing > span > div > div')\n",
    "        \n",
    "        if len(data) == 1000:\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            page_item = driver.find_element(By.CSS_SELECTOR, 'body > div > div.main-container.container.js-quickedit-main-content > div > section > div.region.region-content > div > div > nav > ul > li.pager__item.pager__item--next')\n",
    "            next_link = page_item.find_element(By.CSS_SELECTOR, 'a')\n",
    "            start_url = next_link.get_attribute('href')\n",
    "            scrape_data(cards)\n",
    "            driver.get(start_url)\n",
    "            print(len(data))\n",
    "            print(f\"page_{i}\")\n",
    "            i += 1\n",
    "        except NoSuchElementException :\n",
    "            scrape_data(cards)\n",
    "            print(len(data))\n",
    "            print(f\"page_{i}\")\n",
    "            i += 1\n",
    "            break\n",
    "    except:\n",
    "        print(\"Une erreur s'est produit lors de la collecte sur AICI\")\n",
    "        break\n",
    "\n",
    "print(\"fin du scraping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "data\n",
    "\n",
    "import locale\n",
    "# Définir la locale en français\n",
    "locale.setlocale(locale.LC_TIME, 'fr_FR.UTF-8')\n",
    "\n",
    "# Obtenir la date et l'heure actuelles\n",
    "current_datetime = datetime.now()\n",
    "formatted_date = current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "formatted_month = current_datetime.strftime(\"%B\")\n",
    "formatted_day = current_datetime.strftime(\"%d\")\n",
    "\n",
    "\n",
    "import platform\n",
    "if platform.system() == 'Windows':\n",
    "    dynamic_path = f'D:\\\\Bureau\\\\MemoiresStages\\\\Travaux_techniques\\\\Scrapping\\\\Datasets\\\\{formatted_month}\\\\{formatted_day}_{formatted_month}\\\\AICI_{formatted_day}_{formatted_month}.csv'\n",
    "else:\n",
    "    dynamic_path = f'/mnt/d/Bureau/MemoiresStages/Travaux_techniques/Scrapping/Datasets/{formatted_month}/{formatted_day}_{formatted_month}/AICI_{formatted_day}_{formatted_month}.csv'\n",
    "\n",
    "os.makedirs(os.path.dirname(dynamic_path), exist_ok=True)\n",
    "\n",
    "data.to_csv(dynamic_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
