{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COORESPONDANCE DES FICHIERS COLLECTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_de_collecte</th>\n",
       "      <th>Code_site</th>\n",
       "      <th>Libelle_du_produit</th>\n",
       "      <th>Code produit</th>\n",
       "      <th>Quantite</th>\n",
       "      <th>Prix_du_produit</th>\n",
       "      <th>Caracteristique</th>\n",
       "      <th>Unite</th>\n",
       "      <th>Unite_monetaire</th>\n",
       "      <th>Code</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-09 04:02:44</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>HARICOT BLANC VRAC [300G]</td>\n",
       "      <td>1010703020301</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>Pas de Caracteristique</td>\n",
       "      <td>G</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>Ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-09 04:05:09</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>CARTON DE COTE DE PORC (STERNUM) [10KG]</td>\n",
       "      <td>1010203010201</td>\n",
       "      <td>10</td>\n",
       "      <td>13.000 12.000</td>\n",
       "      <td>Pas de Caracteristique</td>\n",
       "      <td>KG</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-09 04:05:20</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>COTES DE PORC SANS PEAU [500G]</td>\n",
       "      <td>1010203010201</td>\n",
       "      <td>500</td>\n",
       "      <td>1.600</td>\n",
       "      <td>Le porc contient plusieurs nutriments essentie...</td>\n",
       "      <td>G</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-09 04:05:23</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>COTES/COTELETTES DE BOEUF FUMÉES [1/2KG]</td>\n",
       "      <td>1010201010101</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100</td>\n",
       "      <td>Pas de Caracteristique</td>\n",
       "      <td>KG</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-09 04:05:37</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>ÉCHINE DE PORC [500G]</td>\n",
       "      <td>1010203010201</td>\n",
       "      <td>500</td>\n",
       "      <td>1.500 1.000</td>\n",
       "      <td>Tirée de la partie supérieure du cou, l’échine...</td>\n",
       "      <td>G</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_de_collecte Code_site                        Libelle_du_produit  \\\n",
       "0  2024-03-09 04:02:44   adjovan                 HARICOT BLANC VRAC [300G]   \n",
       "1  2024-03-09 04:05:09   adjovan   CARTON DE COTE DE PORC (STERNUM) [10KG]   \n",
       "2  2024-03-09 04:05:20   adjovan            COTES DE PORC SANS PEAU [500G]   \n",
       "3  2024-03-09 04:05:23   adjovan  COTES/COTELETTES DE BOEUF FUMÉES [1/2KG]   \n",
       "4  2024-03-09 04:05:37   adjovan                     ÉCHINE DE PORC [500G]   \n",
       "\n",
       "    Code produit Quantite Prix_du_produit  \\\n",
       "0  1010703020301      300             500   \n",
       "1  1010203010201       10   13.000 12.000   \n",
       "2  1010203010201      500           1.600   \n",
       "3  1010201010101        1           1.100   \n",
       "4  1010203010201      500     1.500 1.000   \n",
       "\n",
       "                                     Caracteristique Unite Unite_monetaire  \\\n",
       "0                             Pas de Caracteristique     G             CFA   \n",
       "1                             Pas de Caracteristique    KG             CFA   \n",
       "2  Le porc contient plusieurs nutriments essentie...     G             CFA   \n",
       "3                             Pas de Caracteristique    KG             CFA   \n",
       "4  Tirée de la partie supérieure du cou, l’échine...     G             CFA   \n",
       "\n",
       "     Code                               Observation  \n",
       "0  111111  Ce produit figure dans le panier de bien  \n",
       "1  111111  ce produit figure dans le panier de bien  \n",
       "2  111111  ce produit figure dans le panier de bien  \n",
       "3  111111          ce produit figure dans le panier  \n",
       "4  111111  ce produit figure dans le panier de bien  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panier_df = pd.read_excel(\"Echantillon_Data_Scrapping_09032024_valide_code.xlsx\")\n",
    "panier_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COORESPONDANCE AVEC LE PANIER DE BIEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_10032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_15032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_16032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_17032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_19032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_24032024.xlsx n'existe pas.\n"
     ]
    }
   ],
   "source": [
    "colonnes_a_comparer = [\"Libelle_du_produit\"] \n",
    "\n",
    "date_debut = datetime.strptime(\"01-03-2024\", \"%d-%m-%Y\")  \n",
    "date_fin = datetime.strptime(\"30-03-2024\", \"%d-%m-%Y\")  \n",
    "# Traiter les intervalles de prix pour obtenir le plus petit prix\n",
    "def extract_min_price(value):\n",
    "    if isinstance(value, str):\n",
    "        if \"-\" in value:\n",
    "            parts = value.split(\"-\")\n",
    "            if len(parts) >= 2:\n",
    "                return int(parts[0].strip())\n",
    "        elif \" \" in value:\n",
    "            return int(value.split()[0])\n",
    "    return value\n",
    "\n",
    "while date_debut <= date_fin:\n",
    "    date_str = date_debut.strftime(\"%d%m%Y\")\n",
    "    fichier_journalier = os.path.join(\"Data_Collecte\",\"mars\", f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "    try:\n",
    "        df_journalier = pd.read_excel(fichier_journalier)\n",
    "        \n",
    "        lignes_correspondantes = pd.merge(df_journalier, panier_df[['Libelle_du_produit', 'Code produit', 'Code']], how=\"inner\", on=colonnes_a_comparer)\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].fillna(\"\")\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(lambda x: x.replace(\".\", \"\") if isinstance(x, str) else x)\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(lambda x: x.replace(\",\", \"\") if isinstance(x, str) else x)\n",
    "        #lignes_correspondantes[\"Prix_du_produit\"] = pd.to_numeric(lignes_correspondantes[\"Prix_du_produit\"].str.replace(\"[^\\d-]\", \"\", regex=True), errors='coerce')\n",
    "        #lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(lambda x: float(x.split(\"-\")[0]) if isinstance(x, str) and \"-\" in x else x)\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(extract_min_price)\n",
    "        \n",
    "        fichier_sortie = os.path.join(\"Data_Valide_Prix\",\"mars\",f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "        lignes_correspondantes.to_excel(fichier_sortie, index=False)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier {fichier_journalier} n'existe pas.\")\n",
    " \n",
    "    date_debut += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FUSION ET AGGREGATION DES DONNEES DU MOIS PRECEDENT(Mars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_10032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_15032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_16032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_17032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_19032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_24032024.xlsx n'existe pas.\n"
     ]
    }
   ],
   "source": [
    "#AJOUT DES TYPES DE VARIETE AUX COLLECTES JOURNALIERES\n",
    "panier_df2 = pd.read_excel(\"Panier_renomme.xlsx\")\n",
    "def clean_and_convert(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    elif isinstance(value, (int, float)):\n",
    "        return int(value)  \n",
    "    elif isinstance(value, str):\n",
    "        try:\n",
    "            numeric_part = re.search(r'\\d+', value).group()  \n",
    "            return int(numeric_part) \n",
    "        except (TypeError, AttributeError, ValueError):\n",
    "            return np.nan  \n",
    "'''  \n",
    "def mean_ignore_nan(values):\n",
    "    if values.isnull().all():\n",
    "        return np.nan\n",
    "    return np.nanmean(values)\n",
    "'''\n",
    "\n",
    "date_debut = datetime.strptime(\"01-03-2024\", \"%d-%m-%Y\")  \n",
    "date_fin = datetime.strptime(\"30-03-2024\", \"%d-%m-%Y\")\n",
    "\n",
    "while date_debut <= date_fin:\n",
    "    date_str = date_debut.strftime(\"%d%m%Y\")\n",
    "    fichier_journalier = os.path.join(\"Data_Valide_Prix\",\"mars\", f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "    try:\n",
    "        df_journalier = pd.read_excel(fichier_journalier)\n",
    "        \n",
    "        df_journalier['Prix_du_produit'] = df_journalier['Prix_du_produit'].apply(clean_and_convert)\n",
    "        df_journalier['Unite_monetaire'] ='CFA'\n",
    "        #df_journalier['Date_de_collecte'] = pd.to_datetime(df_journalier['Date_de_collecte'])\n",
    "        premiere_date = df_journalier.loc[0, 'Date_de_collecte'].split()[0]\n",
    "        df_journalier['Date_de_collecte'] = premiere_date\n",
    "        #donnees_groupees = df_journalier.groupby(['Date_de_collecte','Unite_monetaire','Libelle_du_produit']).agg({'Prix_du_produit': 'mean'}).reset_index()\n",
    "        donnees_groupees2 = pd.merge(df_journalier, panier_df2[['Code produit','Type variété (HE, O1,O2,O3)']], how=\"inner\", on=\"Code produit\")\n",
    "        #donnees_groupees = df_journalier.groupby(['Date_de_collecte', 'Unite_monetaire', 'Code produit']).agg({'Prix_du_produit': mean_ignore_nan}).reset_index()\n",
    "        #print(f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "        fichier_sortie = os.path.join(\"Data_correction1\",\"mars\",f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "        donnees_groupees2.to_excel(fichier_sortie, index=False)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier {fichier_journalier} n'existe pas.\")\n",
    " \n",
    "    date_debut += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION DE TOUS LES FICHIERS DU MOIS PRECEDENT\n",
    "dossier = os.path.join(\"Data_correction1\",\"mars\")\n",
    "dfs = []\n",
    "\n",
    "for fichier in os.listdir(dossier):\n",
    "        \n",
    "        chemin_complet = os.path.join(dossier, fichier)\n",
    "        df = pd.read_excel(chemin_complet)\n",
    "        dfs.append(df)\n",
    "\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "path_out = os.path.join(\"Data_correction1\",\"mars\",\"F_Data_Scrapping_Mars.xlsx\")\n",
    "df_final.to_excel(path_out, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGGREGATION DES DONNEES DU FICHIER DU MOIS PAR PRIX ET AJOUT DE LA COLONNE \"FOURCHETTE\".\n",
    "\n",
    "# Calculer les fourchettes pour chaque produit\n",
    "def calculate_price_ranges(row):\n",
    "    price = row['Prix_du_produit']\n",
    "    \n",
    "    if row['Type variété (HE, O1,O2,O3)'] == 'Heterogene':\n",
    "        lower_bound = price * 0.85\n",
    "        upper_bound = price * 1.15\n",
    "    elif row['Type variété (HE, O1,O2,O3)'] == 'Homogene':\n",
    "        lower_bound = price * 0.70\n",
    "        upper_bound = price * 1.30\n",
    "    else:\n",
    "        raise ValueError(f\"Variété non reconnue pour le produit {row['Libelle_du_produit']}\")\n",
    "    \n",
    "    return f\"{lower_bound:.2f}-{upper_bound:.2f}\"\n",
    "\n",
    "path1 = os.path.join(\"Data_correction1\",\"mars\",\"F_Data_Scrapping_Mars.xlsx\")\n",
    "df_FDSM = pd.read_excel(path1)\n",
    "df_FDSM['Unite_monetaire'] ='CFA'\n",
    "premiere_date = df_FDSM.loc[0, 'Date_de_collecte'].split()[0]\n",
    "df_FDSM['Date_de_collecte'] = premiere_date\n",
    "df_FDSM_A = df_FDSM.groupby(['Date_de_collecte','Libelle_du_produit','Unite_monetaire','Type variété (HE, O1,O2,O3)']).agg({'Prix_du_produit': 'mean'}).reset_index()\n",
    "df_FDSM_A['fourchette'] =df_FDSM_A.apply(calculate_price_ranges, axis=1)\n",
    "path_out = os.path.join(\"Data_correction1\",\"mars\",\"A_Data_Scrapping_Avril.xlsx\")\n",
    "df_FDSM_A.to_excel(path_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CORRECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Control sur les prix selon la fourchette attribuée à la variété"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_month_file = os.path.join(\"Data_correction1\",\"mars\",\"A_Data_Scrapping_Avril.xlsx\")\n",
    "\n",
    "aggregated_df = pd.read_excel(previous_month_file)\n",
    "\n",
    "# Créer un dictionnaire pour un accès rapide aux fourchettes\n",
    "price_ranges = {}\n",
    "\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    lower_bound, upper_bound = map(float, row['fourchette'].split('-')) \n",
    "    price_ranges[row['Libelle_du_produit']] = (lower_bound, upper_bound)\n",
    "\n",
    "# Fonction pour vérifier si le prix est dans la fourchette\n",
    "def is_within_range(product, price):\n",
    "    if product not in price_ranges:\n",
    "        return None\n",
    "    lower_bound, upper_bound = price_ranges[product]\n",
    "    return lower_bound <= price <= upper_bound\n",
    "\n",
    "# Répertoire contenant les fichiers journaliers du mois suivant\n",
    "daily_files_directory= os.path.join(\"Data_correction1\",\"avril\")\n",
    "\n",
    "# Parcourir chaque fichier journalier\n",
    "for daily_file in os.listdir(daily_files_directory):\n",
    "    if daily_file.endswith('.xlsx') : \n",
    "        daily_file_path = os.path.join(daily_files_directory, daily_file)\n",
    "        daily_df = pd.read_excel(daily_file_path)\n",
    "\n",
    "        # Créer une liste des lignes à conserver\n",
    "        rows_to_keep = []\n",
    "\n",
    "        for _, row in daily_df.iterrows():\n",
    "            product = row['Libelle_du_produit']\n",
    "            if product in price_ranges:\n",
    "                price = row['Prix_du_produit']\n",
    "                if pd.notna(price) and not is_within_range(product, price):\n",
    "                    row['Prix_du_produit'] = None\n",
    "                rows_to_keep.append(row)\n",
    "            else:\n",
    "                # Produit non présent dans le fichier du mois précédent\n",
    "                continue\n",
    "\n",
    "        # Convertir la liste des lignes à conserver en DataFrame\n",
    "        cleaned_df = pd.DataFrame(rows_to_keep, columns=daily_df.columns)\n",
    "\n",
    "        # Sauvegarder le fichier nettoyé\n",
    "        cleaned_file_path = os.path.join(\"Data_Correction2\",\"avril\",daily_file)\n",
    "        cleaned_df.to_excel(cleaned_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRIATEMENT D'IMPUTATION DES PRIX MANQUANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 10:53:28,364 - INFO - Fichier agrégé du mois précédent chargé.\n",
      "2024-06-03 10:53:28,368 - INFO - Début du traitement des fichiers journaliers.\n",
      "2024-06-03 10:53:29,078 - INFO - Traitement du fichier Data_Scrapping_02042024.xlsx.\n",
      "2024-06-03 10:53:29,535 - INFO - Imputation faite pour Beurre doux gastronomique avec le nouveau prix 94885.99736380122.\n",
      "2024-06-03 10:53:29,918 - INFO - Imputation faite pour Beurre doux gastronomique avec le nouveau prix 431214.6656434737.\n",
      "2024-06-03 10:53:30,318 - INFO - Imputation faite pour Beurre doux gastronomique avec le nouveau prix 2024813.8530419176.\n",
      "2024-06-03 10:53:30,851 - INFO - Imputation faite pour Beurre doux gastronomique avec le nouveau prix 9571184.892919725.\n",
      "2024-06-03 10:53:31,322 - INFO - Imputation faite pour Beurre doux gastronomique avec le nouveau prix 45285414.37738995.\n",
      "2024-06-03 10:53:31,746 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 148413458.68752244.\n",
      "2024-06-03 10:53:32,163 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 531693142.3562503.\n",
      "2024-06-03 10:53:32,579 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 1903797501.150833.\n",
      "2024-06-03 10:53:33,091 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 6813163162.711079.\n",
      "2024-06-03 10:53:33,552 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 24369371719.25546.\n",
      "2024-06-03 10:53:33,977 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 87117881729.70409.\n",
      "2024-06-03 10:53:34,516 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 311270420032.54443.\n",
      "2024-06-03 10:53:34,972 - INFO - Imputation faite pour Beurre doux avec le nouveau prix 1111568329614.7302.\n",
      "2024-06-03 10:53:35,391 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 692208108295.4513.\n",
      "2024-06-03 10:53:35,828 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 1001840685177.1508.\n",
      "2024-06-03 10:53:36,352 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 1449643491451.9602.\n",
      "2024-06-03 10:53:36,784 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 2097125605210.7544.\n",
      "2024-06-03 10:53:37,176 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 3033112280525.1895.\n",
      "2024-06-03 10:53:37,684 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 4385846903291.152.\n",
      "2024-06-03 10:53:38,235 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 6340441610035.737.\n",
      "2024-06-03 10:53:38,640 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 9164034809307.748.\n",
      "2024-06-03 10:53:39,159 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 13242051093450.326.\n",
      "2024-06-03 10:53:39,692 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 19130451399431.996.\n",
      "2024-06-03 10:53:40,163 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 27631007987066.246.\n",
      "2024-06-03 10:53:40,809 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 39899726057468.35.\n",
      "2024-06-03 10:53:41,541 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 57602972723365.484.\n",
      "2024-06-03 10:53:42,164 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 83142254898445.42.\n",
      "2024-06-03 10:53:42,877 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 119977758035580.05.\n",
      "2024-06-03 10:53:43,755 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 173093934055973.6.\n",
      "2024-06-03 10:53:44,170 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 249669355085598.28.\n",
      "2024-06-03 10:53:44,482 - INFO - Imputation faite pour Crème défrisante avec le nouveau prix 360040234542584.9.\n",
      "2024-06-03 10:53:44,829 - INFO - Imputation faite pour Crème en spray avec le nouveau prix nan.\n",
      "2024-06-03 10:53:45,250 - INFO - Imputation faite pour Crème en spray avec le nouveau prix nan.\n",
      "2024-06-03 10:53:45,652 - INFO - Imputation faite pour Crème en spray avec le nouveau prix nan.\n",
      "2024-06-03 10:53:46,104 - INFO - Imputation faite pour Crème en spray avec le nouveau prix nan.\n",
      "2024-06-03 10:53:46,528 - INFO - Imputation faite pour Dentifrice herbal avec le nouveau prix 374537643221217.5.\n",
      "2024-06-03 10:53:47,044 - INFO - Imputation faite pour Dentifrice herbal avec le nouveau prix 493751608177128.75.\n",
      "2024-06-03 10:53:47,519 - INFO - Imputation faite pour Dentifrice herbal avec le nouveau prix 650796060550417.0.\n",
      "2024-06-03 10:53:47,929 - INFO - Imputation faite pour Dentifrice herbal avec le nouveau prix 857639447703541.9.\n",
      "2024-06-03 10:53:48,380 - INFO - Imputation faite pour Dentifrice herbal avec le nouveau prix 1130025179836985.5.\n",
      "2024-06-03 10:53:48,786 - INFO - Imputation faite pour Dentifrice herbal avec le nouveau prix 1488658667497251.2.\n",
      "2024-06-03 10:53:49,276 - INFO - Imputation faite pour Dentifrice avec le nouveau prix 2304212844921907.0.\n",
      "2024-06-03 10:53:49,667 - INFO - Imputation faite pour Dentifrice avec le nouveau prix 3162628628008063.5.\n",
      "2024-06-03 10:53:50,125 - INFO - Imputation faite pour Dentifrice fraîcheur menthe avec le nouveau prix 2469908873667910.0.\n",
      "2024-06-03 10:53:50,545 - INFO - Imputation faite pour Dentifrice fraîcheur menthe avec le nouveau prix 2992032640416555.0.\n",
      "2024-06-03 10:53:50,957 - INFO - Imputation faite pour Dentifrice fraîcheur menthe avec le nouveau prix 3624070543140145.5.\n",
      "2024-06-03 10:53:51,398 - INFO - Imputation faite pour Dentifrice fraîcheur menthe avec le nouveau prix 4389064373597186.0.\n",
      "2024-06-03 10:53:51,813 - INFO - Imputation faite pour Dentifrice fraîcheur menthe avec le nouveau prix 5314866050853231.0.\n",
      "2024-06-03 10:53:52,257 - INFO - Imputation faite pour Dentifrice fraîcheur menthe avec le nouveau prix 6435137551057188.0.\n",
      "2024-06-03 10:53:52,662 - INFO - Imputation faite pour Dentifrice cavity fighter avec le nouveau prix 1.3021360940269348e+16.\n",
      "2024-06-03 10:53:53,074 - INFO - Imputation faite pour Dentifrice cavity fighter avec le nouveau prix 1.7608538418503092e+16.\n",
      "2024-06-03 10:53:53,512 - INFO - Imputation faite pour Dentifrice maximum cavity protection avec le nouveau prix 2.7775069735264056e+16.\n",
      "2024-06-03 10:53:53,965 - INFO - Imputation faite pour Dentifrice maximum cavity protection avec le nouveau prix 3.9177308232875176e+16.\n",
      "2024-06-03 10:53:54,457 - INFO - Imputation faite pour Tarte aux fromages avec le nouveau prix nan.\n",
      "2024-06-03 10:53:54,895 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 3.67289031556661e+16.\n",
      "2024-06-03 10:53:55,313 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 4.672924205819411e+16.\n",
      "2024-06-03 10:53:55,744 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 5.94432371376637e+16.\n",
      "2024-06-03 10:53:56,181 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 7.560476902274867e+16.\n",
      "2024-06-03 10:53:56,609 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 9.614551714845414e+16.\n",
      "2024-06-03 10:53:57,035 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.2224809059458942e+17.\n",
      "2024-06-03 10:53:57,576 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.5541338193503514e+17.\n",
      "2024-06-03 10:53:58,044 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.975459386048406e+17.\n",
      "2024-06-03 10:53:58,492 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 2.5106215516222944e+17.\n",
      "2024-06-03 10:53:58,934 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 3.190273660105226e+17.\n",
      "2024-06-03 10:53:59,349 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 4.053295322390506e+17.\n",
      "2024-06-03 10:53:59,879 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 5.148992574056068e+17.\n",
      "2024-06-03 10:54:00,459 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 6.539884479268468e+17.\n",
      "2024-06-03 10:54:00,954 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 8.305231964688753e+17.\n",
      "2024-06-03 10:54:01,383 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.0545505908811876e+18.\n",
      "2024-06-03 10:54:01,941 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.3388043634482322e+18.\n",
      "2024-06-03 10:54:02,420 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.6994208816313236e+18.\n",
      "2024-06-03 10:54:02,921 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 2.1568453030896904e+18.\n",
      "2024-06-03 10:54:03,367 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 2.7369782301903483e+18.\n",
      "2024-06-03 10:54:03,837 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 3.472626477235808e+18.\n",
      "2024-06-03 10:54:04,325 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 4.4053383323395287e+18.\n",
      "2024-06-03 10:54:04,834 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 5.587724869795213e+18.\n",
      "2024-06-03 10:54:05,245 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 7.086395601231752e+18.\n",
      "2024-06-03 10:54:05,713 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 8.985670499045891e+18.\n",
      "2024-06-03 10:54:06,117 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.1392273016936663e+19.\n",
      "2024-06-03 10:54:06,518 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.4441262480873368e+19.\n",
      "2024-06-03 10:54:06,984 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.8303532042247373e+19.\n",
      "2024-06-03 10:54:07,445 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 2.319528394382886e+19.\n",
      "2024-06-03 10:54:07,867 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 2.939000177330327e+19.\n",
      "2024-06-03 10:54:08,369 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 3.723357549496828e+19.\n",
      "2024-06-03 10:54:08,834 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 4.716340669663204e+19.\n",
      "2024-06-03 10:54:09,299 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 5.973253790885814e+19.\n",
      "2024-06-03 10:54:09,743 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 7.564012268670447e+19.\n",
      "2024-06-03 10:54:10,265 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 9.57698970446129e+19.\n",
      "2024-06-03 10:54:10,731 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.2123874625161118e+20.\n",
      "2024-06-03 10:54:11,217 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.5345800714765245e+20.\n",
      "2024-06-03 10:54:11,788 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 1.942108342570748e+20.\n",
      "2024-06-03 10:54:12,282 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 2.457498248259298e+20.\n",
      "2024-06-03 10:54:12,742 - INFO - Imputation faite pour Mayonnaise avec le nouveau prix 3.1092018976394537e+20.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 62\u001b[0m\n\u001b[0;32m     58\u001b[0m df_daily \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(daily_file_path)\n\u001b[0;32m     60\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraitement du fichier \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 62\u001b[0m impute_missing_prices(df_daily, df_prev_month)\n\u001b[0;32m     64\u001b[0m corrected_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_clean\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m df_daily\u001b[38;5;241m.\u001b[39mto_excel(corrected_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[16], line 29\u001b[0m, in \u001b[0;36mimpute_missing_prices\u001b[1;34m(df_daily, df_prev_month)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, same_variety_row \u001b[38;5;129;01min\u001b[39;00m same_variety_products\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     28\u001b[0m     same_variety_product \u001b[38;5;241m=\u001b[39m same_variety_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLibelle_du_produit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 29\u001b[0m     prev_same_variety_row \u001b[38;5;241m=\u001b[39m df_prev_month[df_prev_month[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLibelle_du_produit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m same_variety_product]\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m prev_same_variety_row\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     31\u001b[0m         prev_same_variety_price \u001b[38;5;241m=\u001b[39m prev_same_variety_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrix_du_produit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3752\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3750\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_bool_array(key)\n\u001b[0;32m   3754\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3755\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3756\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3811\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   3810\u001b[0m indexer \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 3811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_with_is_copy\u001b[39m(\u001b[38;5;28mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m   3941\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3942\u001b[0m \u001b[38;5;124;03m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3943\u001b[0m \u001b[38;5;124;03m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3946\u001b[0m \u001b[38;5;124;03m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3947\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3948\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take(indices\u001b[38;5;241m=\u001b[39mindices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3950\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m result\u001b[38;5;241m.\u001b[39m_get_axis(axis)\u001b[38;5;241m.\u001b[39mequals(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3924\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3925\u001b[0m         axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3926\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m indices\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3927\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write()\n\u001b[0;32m   3928\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_range_indexer(indices, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))\n\u001b[0;32m   3929\u001b[0m     ):\n\u001b[0;32m   3930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m-> 3932\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[0;32m   3933\u001b[0m     indices,\n\u001b[0;32m   3934\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[0;32m   3935\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   3936\u001b[0m     convert_indices\u001b[38;5;241m=\u001b[39mconvert_indices,\n\u001b[0;32m   3937\u001b[0m )\n\u001b[0;32m   3938\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    960\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[0;32m    962\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 963\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    964\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[0;32m    965\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[0;32m    966\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m    967\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    968\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    969\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\dell\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:764\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    761\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(new_blocks, new_axes)\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;66;03m# We can avoid the need to rebuild these\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blknos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    765\u001b[0m     new_mgr\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_mgr\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Configurer le journal\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "file_prev_month = os.path.join(\"Data_correction1\",\"mars\",\"A_Data_Scrapping_Avril.xlsx\")\n",
    "df_prev_month = pd.read_excel(file_prev_month)\n",
    "\n",
    "logging.info(\"Fichier agrégé du mois précédent chargé.\")\n",
    "\n",
    "# Fonction pour l'imputation des prix manquants\n",
    "def impute_missing_prices(df_daily, df_prev_month):\n",
    "    for index, row in df_daily.iterrows():\n",
    "        if pd.isna(row[\"Prix_du_produit\"]):\n",
    "            product = row[\"Libelle_du_produit\"]\n",
    "            prev_price_row = df_prev_month[df_prev_month[\"Libelle_du_produit\"] == product]\n",
    "            if not prev_price_row.empty:\n",
    "                prev_price = prev_price_row[\"Prix_du_produit\"].values[0]\n",
    "                variety = prev_price_row[\"Type variété (HE, O1,O2,O3)\"].values[0]\n",
    "                \n",
    "                # Filtrer les produits de la même variété dans le fichier journalier\n",
    "                same_variety_products = df_daily[df_daily[\"Type variété (HE, O1,O2,O3)\"] == variety]\n",
    "                # Exclure les produits avec des prix manquants\n",
    "                same_variety_products = same_variety_products.dropna(subset=[\"Prix_du_produit\"])\n",
    "                \n",
    "                if not same_variety_products.empty:\n",
    "                    # Calculer les variations individuelles de chaque produit de la même variété\n",
    "                    variations = []\n",
    "                    for _, same_variety_row in same_variety_products.iterrows():\n",
    "                        same_variety_product = same_variety_row[\"Libelle_du_produit\"]\n",
    "                        prev_same_variety_row = df_prev_month[df_prev_month[\"Libelle_du_produit\"] == same_variety_product]\n",
    "                        if not prev_same_variety_row.empty:\n",
    "                            prev_same_variety_price = prev_same_variety_row[\"Prix_du_produit\"].values[0]\n",
    "                            current_price = same_variety_row[\"Prix_du_produit\"]\n",
    "                            variation = abs(current_price - prev_same_variety_price)\n",
    "                            variations.append(variation)\n",
    "                    \n",
    "                    # Calculer la variation moyenne\n",
    "                    if variations:\n",
    "                        avg_variation = sum(variations) / len(variations)\n",
    "                        new_price = prev_price * avg_variation\n",
    "                        df_daily.at[index, \"Prix_du_produit\"] = new_price\n",
    "                        logging.info(f\"Imputation faite pour {product} avec le nouveau prix {new_price}.\")\n",
    "                else:\n",
    "\n",
    "                    logging.info(f\"Aucun produit similaire trouvé pour la variété {variety}.\")\n",
    "\n",
    "# Parcourir les fichiers journaliers dans le répertoire\n",
    "daily_files_directory = os.path.join(\"Data_Correction2\",\"avril\")\n",
    "output_directory = \"imputation_directory\"\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "logging.info(\"Début du traitement des fichiers journaliers.\")\n",
    "\n",
    "for file_name in os.listdir(daily_files_directory):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        daily_file_path = os.path.join(daily_files_directory, file_name)\n",
    "        df_daily = pd.read_excel(daily_file_path)\n",
    "\n",
    "        logging.info(f\"Traitement du fichier {file_name}.\")\n",
    "\n",
    "        impute_missing_prices(df_daily, df_prev_month)\n",
    "        \n",
    "        corrected_file_path = os.path.join(output_directory, f\"{file_name}_clean\")\n",
    "        df_daily.to_excel(corrected_file_path, index=False)\n",
    "\n",
    "\n",
    "logging.info(\"Traitement terminé.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
