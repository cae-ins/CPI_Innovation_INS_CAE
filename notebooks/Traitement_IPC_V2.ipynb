{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COORESPONDANCE DES FICHIERS COLLECTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import re\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date_de_collecte</th>\n",
       "      <th>Code_site</th>\n",
       "      <th>Libelle_du_produit</th>\n",
       "      <th>Code produit</th>\n",
       "      <th>Quantite</th>\n",
       "      <th>Prix_du_produit</th>\n",
       "      <th>Caracteristique</th>\n",
       "      <th>Unite</th>\n",
       "      <th>Unite_monetaire</th>\n",
       "      <th>Code</th>\n",
       "      <th>Observation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-09 04:02:44</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>HARICOT BLANC VRAC [300G]</td>\n",
       "      <td>1010703020301</td>\n",
       "      <td>300</td>\n",
       "      <td>500</td>\n",
       "      <td>Pas de Caracteristique</td>\n",
       "      <td>G</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>Ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-03-09 04:05:09</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>CARTON DE COTE DE PORC (STERNUM) [10KG]</td>\n",
       "      <td>1010203010201</td>\n",
       "      <td>10</td>\n",
       "      <td>13.000 12.000</td>\n",
       "      <td>Pas de Caracteristique</td>\n",
       "      <td>KG</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-09 04:05:20</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>COTES DE PORC SANS PEAU [500G]</td>\n",
       "      <td>1010203010201</td>\n",
       "      <td>500</td>\n",
       "      <td>1.600</td>\n",
       "      <td>Le porc contient plusieurs nutriments essentie...</td>\n",
       "      <td>G</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-03-09 04:05:23</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>COTES/COTELETTES DE BOEUF FUMÉES [1/2KG]</td>\n",
       "      <td>1010201010101</td>\n",
       "      <td>1</td>\n",
       "      <td>1.100</td>\n",
       "      <td>Pas de Caracteristique</td>\n",
       "      <td>KG</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-03-09 04:05:37</td>\n",
       "      <td>adjovan</td>\n",
       "      <td>ÉCHINE DE PORC [500G]</td>\n",
       "      <td>1010203010201</td>\n",
       "      <td>500</td>\n",
       "      <td>1.500 1.000</td>\n",
       "      <td>Tirée de la partie supérieure du cou, l’échine...</td>\n",
       "      <td>G</td>\n",
       "      <td>CFA</td>\n",
       "      <td>111111</td>\n",
       "      <td>ce produit figure dans le panier de bien</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date_de_collecte Code_site                        Libelle_du_produit  \\\n",
       "0  2024-03-09 04:02:44   adjovan                 HARICOT BLANC VRAC [300G]   \n",
       "1  2024-03-09 04:05:09   adjovan   CARTON DE COTE DE PORC (STERNUM) [10KG]   \n",
       "2  2024-03-09 04:05:20   adjovan            COTES DE PORC SANS PEAU [500G]   \n",
       "3  2024-03-09 04:05:23   adjovan  COTES/COTELETTES DE BOEUF FUMÉES [1/2KG]   \n",
       "4  2024-03-09 04:05:37   adjovan                     ÉCHINE DE PORC [500G]   \n",
       "\n",
       "    Code produit Quantite Prix_du_produit  \\\n",
       "0  1010703020301      300             500   \n",
       "1  1010203010201       10   13.000 12.000   \n",
       "2  1010203010201      500           1.600   \n",
       "3  1010201010101        1           1.100   \n",
       "4  1010203010201      500     1.500 1.000   \n",
       "\n",
       "                                     Caracteristique Unite Unite_monetaire  \\\n",
       "0                             Pas de Caracteristique     G             CFA   \n",
       "1                             Pas de Caracteristique    KG             CFA   \n",
       "2  Le porc contient plusieurs nutriments essentie...     G             CFA   \n",
       "3                             Pas de Caracteristique    KG             CFA   \n",
       "4  Tirée de la partie supérieure du cou, l’échine...     G             CFA   \n",
       "\n",
       "     Code                               Observation  \n",
       "0  111111  Ce produit figure dans le panier de bien  \n",
       "1  111111  ce produit figure dans le panier de bien  \n",
       "2  111111  ce produit figure dans le panier de bien  \n",
       "3  111111          ce produit figure dans le panier  \n",
       "4  111111  ce produit figure dans le panier de bien  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panier_df = pd.read_excel(\"Echantillon_Data_Scrapping_09032024_valide_code.xlsx\")\n",
    "panier_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COORESPONDANCE AVEC LE PANIER DE BIEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_10032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_15032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_16032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_17032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_19032024.xlsx n'existe pas.\n",
      "Le fichier Data_Collecte\\mars\\Data_Scrapping_24032024.xlsx n'existe pas.\n"
     ]
    }
   ],
   "source": [
    "colonnes_a_comparer = [\"Libelle_du_produit\"] \n",
    "\n",
    "date_debut = datetime.strptime(\"01-03-2024\", \"%d-%m-%Y\")  \n",
    "date_fin = datetime.strptime(\"30-03-2024\", \"%d-%m-%Y\")  \n",
    "# Traiter les intervalles de prix pour obtenir le plus petit prix\n",
    "def extract_min_price(value):\n",
    "    if isinstance(value, str):\n",
    "        if \"-\" in value:\n",
    "            parts = value.split(\"-\")\n",
    "            if len(parts) >= 2:\n",
    "                return int(parts[0].strip())\n",
    "        elif \" \" in value:\n",
    "            return int(value.split()[0])\n",
    "    return value\n",
    "\n",
    "while date_debut <= date_fin:\n",
    "    date_str = date_debut.strftime(\"%d%m%Y\")\n",
    "    fichier_journalier = os.path.join(\"Data_Collecte\",\"mars\", f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "    try:\n",
    "        df_journalier = pd.read_excel(fichier_journalier)\n",
    "        \n",
    "        lignes_correspondantes = pd.merge(df_journalier, panier_df[['Libelle_du_produit', 'Code produit', 'Code']], how=\"inner\", on=colonnes_a_comparer)\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].fillna(\"\")\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(lambda x: x.replace(\".\", \"\") if isinstance(x, str) else x)\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(lambda x: x.replace(\",\", \"\") if isinstance(x, str) else x)\n",
    "        #lignes_correspondantes[\"Prix_du_produit\"] = pd.to_numeric(lignes_correspondantes[\"Prix_du_produit\"].str.replace(\"[^\\d-]\", \"\", regex=True), errors='coerce')\n",
    "        #lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(lambda x: float(x.split(\"-\")[0]) if isinstance(x, str) and \"-\" in x else x)\n",
    "        lignes_correspondantes[\"Prix_du_produit\"] = lignes_correspondantes[\"Prix_du_produit\"].apply(extract_min_price)\n",
    "        \n",
    "        fichier_sortie = os.path.join(\"Data_Valide_Prix\",\"mars\",f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "        lignes_correspondantes.to_excel(fichier_sortie, index=False)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier {fichier_journalier} n'existe pas.\")\n",
    " \n",
    "    date_debut += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### FUSION ET AGGREGATION DES DONNEES DU MOIS PRECEDENT(Mars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_10032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_15032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_16032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_17032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_19032024.xlsx n'existe pas.\n",
      "Le fichier Data_Valide_Prix\\mars\\Data_Scrapping_24032024.xlsx n'existe pas.\n"
     ]
    }
   ],
   "source": [
    "#AJOUT DES TYPES DE VARIETE AUX COLLECTES JOURNALIERES\n",
    "panier_df2 = pd.read_excel(\"Panier_renomme.xlsx\")\n",
    "def clean_and_convert(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    elif isinstance(value, (int, float)):\n",
    "        return int(value)  \n",
    "    elif isinstance(value, str):\n",
    "        try:\n",
    "            numeric_part = re.search(r'\\d+', value).group()  \n",
    "            return int(numeric_part) \n",
    "        except (TypeError, AttributeError, ValueError):\n",
    "            return np.nan  \n",
    "'''  \n",
    "def mean_ignore_nan(values):\n",
    "    if values.isnull().all():\n",
    "        return np.nan\n",
    "    return np.nanmean(values)\n",
    "'''\n",
    "\n",
    "date_debut = datetime.strptime(\"01-03-2024\", \"%d-%m-%Y\")  \n",
    "date_fin = datetime.strptime(\"30-03-2024\", \"%d-%m-%Y\")\n",
    "\n",
    "while date_debut <= date_fin:\n",
    "    date_str = date_debut.strftime(\"%d%m%Y\")\n",
    "    fichier_journalier = os.path.join(\"Data_Valide_Prix\",\"mars\", f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "    try:\n",
    "        df_journalier = pd.read_excel(fichier_journalier)\n",
    "        \n",
    "        df_journalier['Prix_du_produit'] = df_journalier['Prix_du_produit'].apply(clean_and_convert)\n",
    "        df_journalier['Unite_monetaire'] ='CFA'\n",
    "        #df_journalier['Date_de_collecte'] = pd.to_datetime(df_journalier['Date_de_collecte'])\n",
    "        premiere_date = df_journalier.loc[0, 'Date_de_collecte'].split()[0]\n",
    "        df_journalier['Date_de_collecte'] = premiere_date\n",
    "        #donnees_groupees = df_journalier.groupby(['Date_de_collecte','Unite_monetaire','Libelle_du_produit']).agg({'Prix_du_produit': 'mean'}).reset_index()\n",
    "        donnees_groupees2 = pd.merge(df_journalier, panier_df2[['Code produit','Type variété (HE, O1,O2,O3)']], how=\"inner\", on=\"Code produit\")\n",
    "        #donnees_groupees = df_journalier.groupby(['Date_de_collecte', 'Unite_monetaire', 'Code produit']).agg({'Prix_du_produit': mean_ignore_nan}).reset_index()\n",
    "        #print(f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "        fichier_sortie = os.path.join(\"Data_correction1\",\"mars\",f\"Data_Scrapping_{date_str}.xlsx\")\n",
    "        donnees_groupees2.to_excel(fichier_sortie, index=False)\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Le fichier {fichier_journalier} n'existe pas.\")\n",
    " \n",
    "    date_debut += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUSION DE TOUS LES FICHIERS DU MOIS PRECEDENT\n",
    "dossier = os.path.join(\"Data_correction1\",\"mars\")\n",
    "dfs = []\n",
    "\n",
    "for fichier in os.listdir(dossier):\n",
    "        \n",
    "        chemin_complet = os.path.join(dossier, fichier)\n",
    "        df = pd.read_excel(chemin_complet)\n",
    "        dfs.append(df)\n",
    "\n",
    "df_final = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "path_out = os.path.join(\"Data_correction1\",\"mars\",\"F_Data_Scrapping_Mars.xlsx\")\n",
    "df_final.to_excel(path_out, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGGREGATION DES DONNEES DU FICHIER DU MOIS PAR PRIX ET AJOUT DE LA COLONNE \"FOURCHETTE\".\n",
    "\n",
    "# Calculer les fourchettes pour chaque produit\n",
    "def calculate_price_ranges(row):\n",
    "    price = row['Prix_du_produit']\n",
    "    \n",
    "    if row['Type variété (HE, O1,O2,O3)'] == 'Heterogene':\n",
    "        lower_bound = price * 0.85\n",
    "        upper_bound = price * 1.15\n",
    "    elif row['Type variété (HE, O1,O2,O3)'] == 'Homogene':\n",
    "        lower_bound = price * 0.70\n",
    "        upper_bound = price * 1.30\n",
    "    else:\n",
    "        raise ValueError(f\"Variété non reconnue pour le produit {row['Libelle_du_produit']}\")\n",
    "    \n",
    "    return f\"{lower_bound:.2f}-{upper_bound:.2f}\"\n",
    "\n",
    "path1 = os.path.join(\"Data_correction1\",\"mars\",\"F_Data_Scrapping_Mars.xlsx\")\n",
    "df_FDSM = pd.read_excel(path1)\n",
    "df_FDSM['Unite_monetaire'] ='CFA'\n",
    "premiere_date = df_FDSM.loc[0, 'Date_de_collecte'].split()[0]\n",
    "df_FDSM['Date_de_collecte'] = premiere_date\n",
    "df_FDSM_A = df_FDSM.groupby(['Date_de_collecte','Libelle_du_produit','Unite_monetaire','Type variété (HE, O1,O2,O3)']).agg({'Prix_du_produit': 'mean'}).reset_index()\n",
    "df_FDSM_A['fourchette'] =df_FDSM_A.apply(calculate_price_ranges, axis=1)\n",
    "path_out = os.path.join(\"Data_correction1\",\"mars\",\"A_Data_Scrapping_Avril.xlsx\")\n",
    "df_FDSM_A.to_excel(path_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CORRECTION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Control sur les prix selon la fourchette attribuée à la variété"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_month_file = os.path.join(\"Data_correction1\",\"mars\",\"A_Data_Scrapping_Avril.xlsx\")\n",
    "\n",
    "aggregated_df = pd.read_excel(previous_month_file)\n",
    "\n",
    "# Créer un dictionnaire pour un accès rapide aux fourchettes\n",
    "price_ranges = {}\n",
    "\n",
    "for _, row in aggregated_df.iterrows():\n",
    "    lower_bound, upper_bound = map(float, row['fourchette'].split('-')) \n",
    "    price_ranges[row['Libelle_du_produit']] = (lower_bound, upper_bound)\n",
    "\n",
    "# Fonction pour vérifier si le prix est dans la fourchette\n",
    "def is_within_range(product, price):\n",
    "    if product not in price_ranges:\n",
    "        return None\n",
    "    lower_bound, upper_bound = price_ranges[product]\n",
    "    return lower_bound <= price <= upper_bound\n",
    "\n",
    "# Répertoire contenant les fichiers journaliers du mois suivant\n",
    "daily_files_directory= os.path.join(\"Data_correction1\",\"avril\")\n",
    "\n",
    "# Parcourir chaque fichier journalier\n",
    "for daily_file in os.listdir(daily_files_directory):\n",
    "    if daily_file.endswith('.xlsx') : \n",
    "        daily_file_path = os.path.join(daily_files_directory, daily_file)\n",
    "        daily_df = pd.read_excel(daily_file_path)\n",
    "\n",
    "        # Créer une liste des lignes à conserver\n",
    "        rows_to_keep = []\n",
    "\n",
    "        for _, row in daily_df.iterrows():\n",
    "            product = row['Libelle_du_produit']\n",
    "            if product in price_ranges:\n",
    "                price = row['Prix_du_produit']\n",
    "                if pd.notna(price) and not is_within_range(product, price):\n",
    "                    row['Prix_du_produit'] = None\n",
    "                rows_to_keep.append(row)\n",
    "            else:\n",
    "                # Produit non présent dans le fichier du mois précédent\n",
    "                continue\n",
    "\n",
    "        # Convertir la liste des lignes à conserver en DataFrame\n",
    "        cleaned_df = pd.DataFrame(rows_to_keep, columns=daily_df.columns)\n",
    "\n",
    "        # Sauvegarder le fichier nettoyé\n",
    "        cleaned_file_path = os.path.join(\"Data_Correction2\",\"avril\",daily_file)\n",
    "        cleaned_df.to_excel(cleaned_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRIATEMENT D'IMPUTATION DES PRIX MANQUANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_prev_month = os.path.join(\"Data_correction1\",\"mars\",\"A_Data_Scrapping_Avril.xlsx\")\n",
    "df_prev_month = pd.read_excel(file_prev_month)\n",
    "\n",
    "# Fonction pour l'imputation des prix manquants\n",
    "def impute_missing_prices(df_daily, df_prev_month):\n",
    "    for index, row in df_daily.iterrows():\n",
    "        if pd.isna(row[\"Prix_du_produit\"]):\n",
    "            product = row[\"Libelle_du_produit\"]\n",
    "            prev_price_row = df_prev_month[df_prev_month[\"Libelle_du_produit\"] == product]\n",
    "            if not prev_price_row.empty:\n",
    "                prev_price = prev_price_row[\"Prix_du_produit\"].values[0]\n",
    "                variety = prev_price_row[\"Type variété (HE, O1,O2,O3)\"].values[0]\n",
    "                \n",
    "                # Filtrer les produits de la même variété dans le fichier journalier\n",
    "                same_variety_products = df_daily[df_daily[\"Type variété (HE, O1,O2,O3)\"] == variety]\n",
    "                # Exclure les produits avec des prix manquants\n",
    "                same_variety_products = same_variety_products.dropna(subset=[\"Prix_du_produit\"])\n",
    "                \n",
    "                if not same_variety_products.empty:\n",
    "                    # Calculer les variations individuelles de chaque produit de la même variété\n",
    "                    variations = []\n",
    "                    for _, same_variety_row in same_variety_products.iterrows():\n",
    "                        same_variety_product = same_variety_row[\"Libelle_du_produit\"]\n",
    "                        prev_same_variety_row = df_prev_month[df_prev_month[\"Libelle_du_produit\"] == same_variety_product]\n",
    "                        if not prev_same_variety_row.empty:\n",
    "                            prev_same_variety_price = prev_same_variety_row[\"Prix_du_produit\"].values[0]\n",
    "                            current_price = same_variety_row[\"Prix_du_produit\"]\n",
    "                            variation = abs(current_price - prev_same_variety_price)\n",
    "                            variations.append(variation)\n",
    "                    \n",
    "                    # Calculer la variation moyenne\n",
    "                    if variations:\n",
    "                        avg_variation = sum(variations) / len(variations)\n",
    "                        new_price = prev_price * avg_variation\n",
    "                        df_daily.at[index, \"Prix_du_produit\"] = new_price\n",
    "\n",
    "# Parcourir les fichiers journaliers dans le répertoire\n",
    "daily_files_directory = os.path.join(\"Data_Correction2\",\"avril\")\n",
    "output_directory = \"imputation_directory\"\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "for file_name in os.listdir(daily_files_directory):\n",
    "    if file_name.endswith(\".xlsx\"):\n",
    "        daily_file_path = os.path.join(daily_files_directory, file_name)\n",
    "        df_daily = pd.read_excel(daily_file_path)\n",
    "        \n",
    "        impute_missing_prices(df_daily, df_prev_month)\n",
    "    \n",
    "        corrected_file_path = os.path.join(output_directory, f\"{file_name}_clean\")\n",
    "        df_daily.to_excel(corrected_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
