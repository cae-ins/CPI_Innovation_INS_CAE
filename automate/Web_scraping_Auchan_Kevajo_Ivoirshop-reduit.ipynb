{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76f68864",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"image_logo.png\" alt=\"Logo du projet\" style=\"width: 150px; height: auto; border-radius: 8px; box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.1);\">\n",
    "</p>\n",
    "\n",
    "<h1 align=\"center\" style=\"color: #FFA500; font-size: 2.5em; font-weight: bold;\">Projet INS_PHAS</h1>\n",
    "\n",
    "<p align=\"center\" style=\"color: #4CAF50; font-size: 1.2em;\">\n",
    "  Collecte des données de prix au moyen des données scrapées et des données scannées.\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" style=\"color: #4CAF50; font-size: 1.1em;\">\n",
    "  <strong>Auteur :</strong> DOUMBIA ABDOULAYE (<a href=\"mailto:abdoulaye.doumbi19@inphb.ci\" style=\"color: #FFA500;\">abdoulaye.doumbi19@inphb.ci</a>)\n",
    "</p>\n",
    "\n",
    "<p align=\"center\" style=\"color: #4CAF50; font-size: 1.1em;\">\n",
    "  Ce matériel est soumis aux termes et conditions de la licence <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\" style=\"color: #FFA500;\">Creative Commons CC BY-NC-SA 4.0</a>. L'utilisation gratuite est autorisée à des fins non commerciales.\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8d242b",
   "metadata": {},
   "source": [
    "# ivoirshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aef3ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "\n",
    "# Liste des URLs à traiter\n",
    "urls = [\"https://www.ivoirshop.ci/\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/supermache\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/maison-bureau\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/telephonie\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/beaute-hygiene\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/electronique\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/produits-adultes\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/mode/mode-femme\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/mode/mode-homme\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/produits-pour-bebes\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/informatique\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/sport-bien-etre\",\n",
    "        \"https://www.ivoirshop.ci/categorie-produit/jouets-et-jeux-videos\"\n",
    "       ]\n",
    "\n",
    "# Liste pour stocker les DataFrames de chaque site\n",
    "all_dfs = []\n",
    "products = []\n",
    "# Boucle à travers chaque URL\n",
    "for url in urls:\n",
    "    # Étape 1 : Envoyer une requête HTTP à la page web et récupérer le contenu HTML\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    # Étape 2 : Utiliser BeautifulSoup pour parser le contenu HTML\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "    # Étape 3 : Extraire les informations des produits\n",
    "    \n",
    "    for product_tag in soup.find_all(\"li\", class_=\"product\"):\n",
    "        product_info = {}\n",
    "        \n",
    "        product_info['N_ordre']=\"\"\n",
    "        product_info[\"Code_ID_PE\"]=\"\"\n",
    "        \n",
    "        product_info['code_site']= url\n",
    "        product_info['date de collecte']= datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "        # Extraire le lien du produit\n",
    "        product_info[\"lien_produit\"] = product_tag.find(\"a\")[\"href\"]\n",
    "\n",
    "        # Extraire le titre du produit\n",
    "        product_info[\"Libellé du produit\"] = product_tag.find(\"h2\", class_=\"woo-loop-product__title\").text.strip()\n",
    "\n",
    "        # Extraire le prix du produit\n",
    "        price_tag = product_tag.find(\"span\", class_=\"price\")\n",
    "        product_info[\"Prix du produit\"] = price_tag.find(\"ins\").text.strip() if price_tag and price_tag.find(\"ins\") else None\n",
    "\n",
    "        # Ajouter les informations du produit à la liste\n",
    "        products.append(product_info)\n",
    "\n",
    "    # Étape 4 : Créer un DataFrame à partir de la liste de produits\n",
    "    df_ivoirshop = pd.DataFrame(products)\n",
    "\n",
    "    # Ajouter le DataFrame à la liste globale\n",
    "    all_dfs.append(df_ivoirshop)\n",
    "df_ivoirshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e25107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_product_info(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=500)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur de connexion à {url} : {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    price_tag = soup.find('p', class_='price')\n",
    "    promo_price_tag = price_tag.find('ins')\n",
    "    promo_price = promo_price_tag.text.strip() if promo_price_tag else None\n",
    "\n",
    "    regular_price_tag = price_tag.find('del')\n",
    "    regular_price = regular_price_tag.text.strip() if regular_price_tag else None\n",
    "\n",
    "    stock_tag = soup.find('p', class_='stock in-stock')\n",
    "    stock = stock_tag.text.strip() if stock_tag else None\n",
    "\n",
    "    description_tag = soup.find('h1', class_='wt-text-body-03')\n",
    "    description = description_tag.text.strip() if description_tag else None\n",
    "    \n",
    "    url_lien = url\n",
    "\n",
    "    # Create a DataFrame with the extracted information\n",
    "    df_product = pd.DataFrame({\n",
    "        \n",
    "        'Prix Réel': [promo_price],\n",
    "        'code_siteDescription': url_lien,\n",
    "        'Quantité': [stock],\n",
    "        'Caractéristiques du produit': [description]\n",
    "    })\n",
    "\n",
    "    return df_product\n",
    "\n",
    "# List of URLs for individual product pages\n",
    "urls = list(df_ivoirshop[\"lien_produit\"])\n",
    "# Initialize an empty DataFrame to store the results\n",
    "combined_df_ivoirshop = pd.DataFrame()\n",
    "\n",
    "# Scrape product information for each URL and concatenate the results\n",
    "for url in urls:\n",
    "    df_product = scrape_product_info(url)\n",
    "    combined_df_ivoirshop = pd.concat([combined_df_ivoirshop, df_product], ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "\n",
    "combined_df_ivoirshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf29335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ivoirshop['Prix Réel'] = combined_df_ivoirshop['Prix Réel']\n",
    "df_ivoirshop['code_siteDescription'] = combined_df_ivoirshop['code_siteDescription'] \n",
    "df_ivoirshop['Quantité'] = combined_df_ivoirshop['Quantité']\n",
    "df_ivoirshop['Caractéristiques du produit'] = combined_df_ivoirshop['Caractéristiques du produit']\n",
    "df_ivoirshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa726ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réorganiser les colonnes selon vos besoins\n",
    "df_ivoirshop = df_ivoirshop[[\n",
    "    'N_ordre', 'code_site', 'Code_ID_PE', 'date de collecte', 'Libellé du produit', 'Caractéristiques du produit',\n",
    "    'Prix Réel', 'Quantité', \"Prix du produit\"]]\n",
    "df_ivoirshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22cc418",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ivoirshop[[\"Prix du produit\", 'Unite_monetaire']] = df_ivoirshop[\"Prix du produit\"].str.extract(r\"([0-9.]+)\\s*([a-zA-Z]+)\")\n",
    "df_ivoirshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ivoirshop.to_excel(\"df_ivoirshop.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c44177",
   "metadata": {},
   "source": [
    "# kevajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223772ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_product_info(product_div):\n",
    "    title_tag = product_div.find('h3', class_='wd-entities-title')\n",
    "    title = title_tag.text.strip() if title_tag else None\n",
    "\n",
    "    price_tag = product_div.find('span', class_='price')\n",
    "    price = price_tag.text.strip() if price_tag else None\n",
    "\n",
    "    promo_tag = product_div.find('span', class_='woocommerce-Price-amount amount')\n",
    "    promo = promo_tag.text.strip() if promo_tag else None\n",
    "\n",
    "    real_price_tag = product_div.find('ins', class_='woocommerce-Price-amount amount')\n",
    "    real_price = real_price_tag.text.strip() if real_price_tag else None\n",
    "\n",
    "    image_tag = product_div.find('img', class_='attachment-600x498')\n",
    "    image_url = image_tag['nitro-lazy-src'] if image_tag and 'nitro-lazy-src' in image_tag.attrs else None\n",
    "\n",
    "    label_tag = product_div.find('span', class_='awl-inner-text')\n",
    "    label = label_tag.text.strip() if label_tag else None\n",
    "    \n",
    "    \n",
    "    brand_tag = product_div.find(\"div\", class_=\"col-12 mt-1 my-md-3 text-center text-md-start jt-max-line-size-3\")\n",
    "    brand = brand_tag.text.strip() if brand_tag else None\n",
    "    \n",
    "    \n",
    "    \n",
    "    quantity_tag = product_div.find('input', class_='js-item-qty')\n",
    "    quantity = quantity_tag['value'] if quantity_tag else None\n",
    "\n",
    "    product_url = product_div.find('a', class_='product-image-link')['href']\n",
    "    date_new=datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    return {\n",
    "        'date de collecte': date_new,\n",
    "        'Libellé du produit': title,\n",
    "        'Prix du produit': price,\n",
    "        'Promo': promo,\n",
    "        'Image URL': image_url,\n",
    "        'URL': product_url\n",
    "    }\n",
    "\n",
    "products_data = []\n",
    "def scrape_page(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=500)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Erreur de connexion à {url} : {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    product_divs = soup.find_all('div', class_='wd-product')\n",
    "    \n",
    "    \n",
    "    for product_div in product_divs:\n",
    "        product_info = scrape_product_info(product_div)\n",
    "        products_data.append(product_info)\n",
    "\n",
    "    return pd.DataFrame(products_data)\n",
    "\n",
    "# URL de la page\n",
    "urls = [\n",
    "    \"https://kevajo.com/\", \"https://kevajo.com/product-category/pour-bebe/\",\n",
    "    \"https://kevajo.com/product-category/mode-2/modefemme/\",\n",
    "\"https://kevajo.com/product-category/mode-2/mode-homme/\",\n",
    "\"https://kevajo.com/product-category/maison-et-cuisine/\",\n",
    "\"https://kevajo.com/product-category/fournitures-de-bureau-et-scolaires/\",\n",
    "\"https://kevajo.com/product-category/telephones-et-tablettes/\",\n",
    "\"https://kevajo.com/product-category/jeux-video-consoles-et-accessoires/\",\n",
    "\"https://kevajo.com/product-category/electronique/\",\n",
    "\"https://kevajo.com/product-category/lunettes-de-vue/\",\n",
    "\"https://kevajo.com/product-category/beaute-et-hygiene/\",\n",
    "\"https://kevajo.com/product-category/informatique/\",\n",
    "\"https://kevajo.com/product-category/auto-et-moto/\",\n",
    "\"https://kevajo.com/product-category/mode-2/bagages-et-sacs-de-voyage/\",\n",
    "\"https://kevajo.com/#\"]\n",
    "\n",
    "# Scrape product information for each URL and concatenate the results\n",
    "for url in urls:\n",
    "    df_product = scrape_page(url)\n",
    "    df_kevajo = pd.concat([ df_product], ignore_index=True)\n",
    "df_kevajo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d61d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def extract_text(element, tag_name=None):\n",
    "    if element and tag_name:\n",
    "        tag = element.find(tag_name)\n",
    "        return tag.text.strip() if tag else \"\"\n",
    "    return \"\"\n",
    "\n",
    "def clean_text(text):\n",
    "    return text.replace('\\r\\n', '').replace('\\xa0', '')\n",
    "\n",
    "def scrape_kevajo_page(page_urls):\n",
    "    product_data_list = []\n",
    "    \n",
    "    for page_url in page_urls:\n",
    "        url_lien=page_url\n",
    "        try:\n",
    "            response = requests.get(page_url, timeout=500)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Erreur de connexion à {page_url} : {e}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extraction des éléments de la page\n",
    "        breadcrumbs = [a.text.strip() for a in soup.select('.woocommerce-breadcrumb a')]\n",
    "        product_title = extract_text(soup.find('h1', class_='product_title'))\n",
    "        \n",
    "\n",
    "        # Extraction de la description\n",
    "        description_tag = soup.find('div', class_='jt-description-content-wrapper')\n",
    "        description = description_tag.find('p').text.strip() if description_tag else None\n",
    "        \n",
    "\n",
    "        attributes = {}\n",
    "        attribute_rows = soup.select('.woocommerce-product-attributes tr')\n",
    "        for row in attribute_rows:\n",
    "            label = row.find('th').text.strip()\n",
    "            value = row.find('td').text.strip()\n",
    "            attributes[label] = value\n",
    "\n",
    "        data = {\n",
    "            'N_ordre': 'index',# Modify as needed\n",
    "            'code_site': url_lien,  # Modify as needed\n",
    "            'Code_ID_PE': 'YourCodeIDPE',  # Modify as needed\n",
    "            'date de collecte': datetime.now().strftime('%Y-%m-%d'),\n",
    "            'Breadcrumbs': breadcrumbs,\n",
    "            'ProductTitle': product_title,\n",
    "            'Attributes': attributes,\n",
    "        }\n",
    "\n",
    "        product_data_list.append(data)\n",
    "\n",
    "    return pd.DataFrame(product_data_list)\n",
    "\n",
    "# Liste des URLs de pages produits\n",
    "page_urls = list(df_kevajo['URL'])\n",
    "\n",
    "# Scrape des détails de chaque page\n",
    "df_product_details = scrape_kevajo_page(page_urls)\n",
    "\n",
    "# Assuming 'Attributes' column contains dictionaries\n",
    "df_product_details['Quantité'] = df_product_details['Attributes'].apply(lambda x: x.get('Poids', ''))\n",
    "df_product_details['Caractéristiques du produit'] = df_product_details['Attributes'].apply(lambda x: x.get('Marque', ''))\n",
    "\n",
    "# Extract 'Poids', 'Unite', and 'Marque' columns from the 'Poids' column\n",
    "df_product_details[['Quantité', 'Unite']] = df_product_details['Quantité'].str.extract(r\"([0-9.]+)\\s*([a-zA-Z]+)\")\n",
    "\n",
    "# Drop the original 'Poids' column\n",
    "#df.drop('Poids', axis=1, inplace=True)\n",
    "\n",
    "# Display the modified DataFrame\n",
    "df_product_details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525caa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac6bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kevajo['N_ordre'] = list(df_product_details[\"N_ordre\"])\n",
    "df_kevajo['code_site'] = list(df_product_details[\"code_site\"])\n",
    "df_kevajo['Code_ID_PE'] = list(df_product_details[\"Code_ID_PE\"])\n",
    "df_kevajo['date de collecte'] = list(df_product_details[\"date de collecte\"])\n",
    "df_kevajo['Caractéristiques du produit'] = list(df_product_details['Caractéristiques du produit'])\n",
    "df_kevajo['Quantité'] = list(df_product_details[\"Quantité\"])\n",
    "df_kevajo['unite de mesure'] = list(df_product_details[\"Unite\"])\n",
    "df_kevajo['Intitule'] = list(df_product_details[\"Breadcrumbs\"])\n",
    "df_kevajo['Entreprise'] = list(df_product_details[\"ProductTitle\"])\n",
    "\n",
    "df_kevajo['Attributes'] = list(df_product_details[\"Attributes\"])\n",
    "df_kevajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1c174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réorganiser les colonnes selon vos besoins\n",
    "df_kevajo = df_kevajo[[\n",
    "    'N_ordre', 'code_site', 'Code_ID_PE', 'date de collecte', 'Libellé du produit', 'Caractéristiques du produit',\n",
    "    'unite de mesure', 'Quantité', \"Prix du produit\"]]\n",
    "df_kevajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d41ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_kevajo[[\"Prix du produit\", 'Unite_monetaire']] = df_kevajo[\"Prix du produit\"].str.extract(r\"([0-9.]+)\\s*([a-zA-Z]+)\")\n",
    "df_kevajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kevajo.to_excel(\"df_ivoirshop.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac282d11",
   "metadata": {},
   "source": [
    "# Auchan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e761a0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Liste des URLs\n",
    "urls = [\n",
    "     #Epicerie Salée\n",
    "     \"https://www.auchan.ci/mes-courses/conserves-et-plats-cuisines/UBO4Q0Q1\",\n",
    "     \"https://www.auchan.ci/mes-courses/pates-riz-semoules-et-purees/UHN6N7N1\",\n",
    "     \"https://www.auchan.ci/mes-courses/huiles-epices-condiments/CQQDSP9P\",\n",
    "     \"https://www.auchan.ci/mes-courses/aperitif/1EN9IQWQ\",\n",
    "\n",
    "    #Epicerie Sucrée\n",
    "     \"https://www.auchan.ci/mes-courses/biscuits-et-gateaux/U5RGPLP1\",\n",
    "     \"https://www.auchan.ci/mes-courses/chocolats-et-bonbons/U75EAPLP\",\n",
    "     \"https://www.auchan.ci/mes-courses/cafes/U0FDIPBP\",\n",
    "     \"https://www.auchan.ci/mes-courses/compotes-fruits-au-sirop-et-cremes-desserts/CJRO6N7N\",\n",
    "     \"https://www.auchan.ci/mes-courses/sucres-farines/CQFLSP9P\",\n",
    "     \"https://www.auchan.ci/mes-courses/petit-dejeuner/CXXH4LOL\",\n",
    "\n",
    "    #Produits laitiers, oeufs et fromages\n",
    "     \"https://www.auchan.ci/mes-courses/fromages-rapes-et-a-cuisiner/1KJ6N5NC\",\n",
    "     \"https://www.auchan.ci/mes-courses/fromages/CV5SB7BU\",\n",
    "     \"https://www.auchan.ci/mes-courses/oeufs-beurres-et-creme/1LOLAN7N\",\n",
    "     \"https://www.auchan.ci/mes-courses/laits-et-boissons-lactees/C7NZMPLP\",\n",
    "     \"https://www.auchan.ci/mes-courses/yaourts-et-desserts/UEX02QWQ\",\n",
    "\n",
    "\n",
    "    #Boulangerie : VIDE\n",
    "    \n",
    "    #Traiteur\n",
    "    \"https://www.auchan.ci/mes-courses/plats-chauds/UODESN7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/plats-froids/1T3PSB5B\",\n",
    "\n",
    "    #Boissons\n",
    "    \"https://www.auchan.ci/mes-courses/boissons-gazeuses-et-sirops/175K2PLP\",\n",
    "    \"https://www.auchan.ci/mes-courses/eaux/19Z32PBP\",\n",
    "    \"https://www.auchan.ci/mes-courses/bieres-et-cidres/UR7QGB7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/liqueurs-et-spiritueux/15K9GPLP\",\n",
    "    \"https://www.auchan.ci/mes-courses/vins/CP7F2B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/champagnes/UX7ZILOL\",\n",
    "\n",
    "    #Surgélés\n",
    "    \"https://www.auchan.ci/mes-courses/pizzas-quiches-et-tartes/1WP6P9PC\",\n",
    "    \"https://www.auchan.ci/mes-courses/frites-et-pommes-de-terre/1JJLIN7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/glaces-patisseries-et-viennoiseries/1B3H4Q0Q\",\n",
    "    \"https://www.auchan.ci/mes-courses/legumes-et-fruits/CRPYAB7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/viandes-et-poissons/1KOD4N5N\",\n",
    "    #Apéritifs, plats cuisinés, produits du monde : VIDE\n",
    "    \"https://www.auchan.ci/mes-courses/plats-cuisines/1P972B7B\",\n",
    "\n",
    "\n",
    "    #Viandes et poissons\n",
    "    \"https://www.auchan.ci/mes-courses/poissonnerie/UWF8AP9P\",\n",
    "    \"https://www.auchan.ci/mes-courses/boucherie/CW9WSP9P\",\n",
    "    \"https://www.auchan.ci/mes-courses/volaille-gibier-lapin-et-autres/UZ9ZSLOL\",\n",
    "    \"https://www.auchan.ci/mes-courses/charcuterie/13NXAPLP\",\n",
    "\n",
    "    #Fruits & Legumes\n",
    "    \"https://www.auchan.ci/mes-courses/fruits-frais/1BF52Q0Q\",\n",
    "    \"https://www.auchan.ci/mes-courses/legumes-frais/CLF04N7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/legumes-frais/CLF04N7N\",\n",
    "    #Prêt à consommer : VIDE,\n",
    "\n",
    "    #Bébé\n",
    "    \"https://www.auchan.ci/mes-courses/toilette-et-soins-du-bebe/1LOYMN7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/couches-lingettes-et-cotons/UWO92P9P\",\n",
    "    \"https://www.auchan.ci/mes-courses/cereales-et-petit-dejeuner-bebe/1Y9Z6B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/repas/CQ98AP9P\",\n",
    "    \"https://www.auchan.ci/mes-courses/desserts-et-gouter/UV9X6B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/jouets-et-eveil/1EEN4QWQ\",\n",
    "\n",
    "    #Hygiène & Beauté\n",
    "    \"https://www.auchan.ci/mes-courses/hygiene-soins-homme/UED6QWQ1\",\n",
    "    \"https://www.auchan.ci/mes-courses/corps/CZ02LOLU\",\n",
    "    \"https://www.auchan.ci/mes-courses/hygiene-dentaire/UJJX2N7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/soins-des-cheveux/UZZNGLOL\",\n",
    "    \"https://www.auchan.ci/mes-courses/hygiene-feminine/UPE76B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/parapharmacie/18PEAELE\",\n",
    "    \"https://www.auchan.ci/mes-courses/papier-et-cotons/CYW96B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/soins-du-visage-et-maquillage/CX99MLOL\",\n",
    "\n",
    "    #Produits ménagers et accessoires de la maison\n",
    "    \"https://www.auchan.ci/mes-courses/produits-nettoyants/1R8P4B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/accessoires-de-cuisine-salle-de-bains-et-wc/U0DBAPBP\",\n",
    "    \"https://www.auchan.ci/mes-courses/accessoires-menagers/C37P2PLP\",\n",
    "    \"https://www.auchan.ci/mes-courses/lessives-repassage-et-soin-du-linge/1KOW2N5N\",\n",
    "    \"https://www.auchan.ci/mes-courses/essuie-tout-et-papiers/1WZE4P9P\",\n",
    "\n",
    "    #Animaux\n",
    "    \"https://www.auchan.ci/mes-courses/chiens/UZZ9GLOL\",\n",
    "    \"https://www.auchan.ci/mes-courses/chats/CRNQAB7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/rongeurs/CJ03SN7N\",\n",
    "\n",
    "    #Maisons & Decos\n",
    "    \"https://www.auchan.ci/mes-courses/maison-et-deco/187E2ELE\",\n",
    "    \"https://www.auchan.ci/mes-courses/cuisine-et-arts-de-la-table/1X78GLOL\",\n",
    "    \"https://www.auchan.ci/mes-courses/literie/ULFZ4N7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/papeterie/CBFT4Q0Q\",\n",
    "    \"https://www.auchan.ci/mes-courses/jardin-et-exterieurs/1BT0SQ0Q\",\n",
    "    \"https://www.auchan.ci/mes-courses/luminaires/CLTF2N7N\",\n",
    "    \"https://www.auchan.ci/mes-courses/stockage-et-rangement/U8XFSELE\",\n",
    "\n",
    "    #Electronique\n",
    "    \"https://www.auchan.ci/mes-courses/accessoires-electroniques/UJFB4N7N\",\n",
    "\n",
    "    #Mode\n",
    "    \"https://www.auchan.ci/mes-courses/mode-femme/1R792B7B\",\n",
    "    \"https://www.auchan.ci/mes-courses/mode-homme/CEDZSQWQ\"\n",
    "\n",
    "    #Jouets & Jeux Vidéos\n",
    "    \"https://www.auchan.ci/mes-courses/jeux-de-societe/U3KK2PLP\",\n",
    "    #JOUETS (VIDE)\n",
    "    #JEUX VIDEOS (VIDE)\n",
    "    #Recharge mobile : pas intégré\n",
    "     \n",
    "     ] \n",
    "\n",
    "# Configuration du navigateur Selenium\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--headless\")  # Pour exécuter le navigateur en arrière-plan\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Initialiser une liste pour stocker les données\n",
    "data_list = []\n",
    "\n",
    "# Parcourir la liste des URLs\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    # Attendre que la page se charge complètement\n",
    "    wait = WebDriverWait(driver, 5000)\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.js-jt-product-card')))\n",
    "\n",
    "    # Parser le contenu HTML avec BeautifulSoup\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "    # Sélectionner tous les produits sur la page\n",
    "    products = soup.select('.js-jt-product-card')\n",
    "\n",
    "    # Boucle sur chaque produit\n",
    "    for product in products:\n",
    "        # Extraire les informations nécessaires\n",
    "        product_pid = product['cy-product-pid']\n",
    "        product_title = product.select_one('.js-title-line').text.strip()\n",
    "        product_brand = product.select_one('.js-brand-line').text.strip()\n",
    "        product_image = product.select_one('.js-image-line')['data-src']\n",
    "        product_price = product.select_one('.js-price-line').text.strip()\n",
    "        product_old_price = product.select_one('.js-wasPrice-line')\n",
    "\n",
    "        url_lien = url\n",
    "\n",
    "        # Vérifier si le prix d'origine existe\n",
    "        if product_old_price:\n",
    "            product_old_price = product_old_price.text.strip()\n",
    "        else:\n",
    "            product_old_price = None\n",
    "\n",
    "        # Ajouter les données à la liste\n",
    "        data_list.append({\n",
    "            'N_ordre': product_pid,\n",
    "            'Libellé': product_title,\n",
    "            'code_site': url_lien,\n",
    "            'Code_ID_PE': product_brand,\n",
    "            'Product Image': product_image,\n",
    "            'Prix du produit': product_price,\n",
    "            'Product Old Price': product_old_price,\n",
    "            'date de collecte': datetime.now().strftime('%Y-%m-%d'),\n",
    "        })\n",
    "\n",
    "        # Cliquer sur l'élément pour obtenir plus de détails\n",
    "        product_link = product.select_one('.js-product-anchor')\n",
    "        if product_link and product_link.has_attr('href'):\n",
    "            product_details_url = product_link['href']\n",
    "\n",
    "            # Ouvrir un nouvel onglet pour charger la page de détails\n",
    "            driver.execute_script(f\"window.open('{product_details_url}', '_blank');\")\n",
    "\n",
    "            # Passer au nouvel onglet\n",
    "            driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "            # Attendre que la page de détails se charge complètement\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, '.jt-breadcrumb-title-ellipsis span:last-child')))\n",
    "\n",
    "            # Parser le contenu HTML de la page de détails\n",
    "            detail_soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "\n",
    "            # Extraire des informations supplémentaires de la page de détails\n",
    "            product_description = detail_soup.select_one('.jt-description-content-wrapper p').text.strip()\n",
    "\n",
    "            # Ajouter les informations supplémentaires à la liste\n",
    "            data_list[-1]['Caractéristiques du produit'] = product_description\n",
    "\n",
    "            # Fermer le nouvel onglet\n",
    "            driver.close()\n",
    "\n",
    "            # Revenir à l'onglet principal\n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "# Fermer le navigateur Selenium\n",
    "driver.quit()\n",
    "\n",
    "# Créer un DataFrame à partir de la liste\n",
    "df_auchan = pd.DataFrame(data_list)\n",
    "\n",
    "# Imprimer le DataFrame\n",
    "df_auchan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Fonction pour extraire le nom du produit, la quantité et l'unité de mesure\n",
    "def extract_info(product_title):\n",
    "    # Utiliser une expression régulière pour extraire les informations\n",
    "    match = re.match(r'(?P<Libellé_du_produit>.*?)(?P<Quantité>\\d+)(?P<Unité_de_mesure>[a-zA-Z]+)', product_title)\n",
    "    \n",
    "    # Vérifier si la correspondance a été trouvée\n",
    "    if match:\n",
    "        return match.group('Libellé_du_produit').strip(), match.group('Quantité'), match.group('Unité_de_mesure')\n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "# Appliquer la fonction sur la colonne \"Product Title\"\n",
    "df_auchan[['Libellé du produit', 'Quantité', 'unite de mesure']] = df_auchan[\"Libellé\"].apply(extract_info).apply(pd.Series)\n",
    "\n",
    "# Imprimer le DataFrame mis à jour\n",
    "df_auchan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réorganiser les colonnes selon vos besoins\n",
    "df_auchan = df_auchan[[\n",
    "    'N_ordre', 'code_site', 'Code_ID_PE', 'date de collecte', 'Libellé du produit', 'Caractéristiques du produit',\n",
    "    'unite de mesure', 'Quantité', \"Prix du produit\"]]\n",
    "df_auchan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e11847",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auchan[[\"Prix du produit\", 'Unite_monetaire']] = df_auchan[\"Prix du produit\"].str.extract(r\"([0-9.]+)\\s*([a-zA-Z]+)\")\n",
    "df_auchan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26078a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_auchan.to_excel(\"df_auchan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35853d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Concaténation verticale (ajout des lignes)\n",
    "Web_scraping_Auchan_Kevajo_Ivoirshop = pd.concat([df_ivoirshop,df_kevajo, df_auchan], ignore_index=True)\n",
    "\n",
    "# Si vous ne souhaitez pas réinitialiser les index, vous pouvez laisser ignore_index=False\n",
    "\n",
    "# Afficher le résultat\n",
    "Web_scraping_Auchan_Kevajo_Ivoirshop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a174f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporter le DataFrame result_df vers un fichier Excel\n",
    "Web_scraping_Auchan_Kevajo_Ivoirshop.to_excel('Web_scraping_Auchan_Kevajo_Ivoirshop.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390bbd83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603886e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
